# 目的

広聴AIやいどばたに応用できるファクトチェックの共通処理を作りたい

https://github.com/digitaldemocracy2030/kouchou-ai/issues/324

# 進め方

- テスト用のコメントのセットを用意する
- 各コメントに対して、以下の正解を手動で用意する
    - 正誤判定
    - 判定理由区分
    - 判定理由詳細
- ファクトチェック処理を最適化する
    - 複数の方法でファクトチェックを実装する
    - プロンプト等のバリエーションを作成する
    - 処理時間/API費用/精度を比較する

# 進捗　2025/04/25

- 仮のテストデータは作成済み（_input/comments.py）
- いくつかの手段でざっくり実装し始めたが、いずれも精度が非常に低い(参考画像 [1](https://github.com/user-attachments/assets/a22f22ed-3c0e-4a09-8a45-0cfb19a43e91) [2](https://github.com/user-attachments/assets/a89788ef-7b85-4633-9dc9-54fc9c0921ba))
- 特定サイト検索、Web検索は完全一致なのでどうしても見逃し率が高くなる
- 今後は、LLM、ファクトチェックサービス、DeepResearchを中心に比較を進める

# 使い方

### 環境構築
- .env.sample をコピーして .env ファイルを作り、自身のAPI_KEYなどを記載する
- `pip3 install -r requirements.txt`

### 実行方法
- _input/comments.py のテスト対象コメントを差し替える
- python3 main.py を実行する
- 判定結果が _output/ に出力される

# 要検討事項

- 共通問題
    - 前処理どうするか？
        - 生のコメントからファクトチェックすべき部分を抽出するのは難しい。
            - 「AだからBだ」→ Aである、自体もチェック対象？
            - 「AなBが好き」→ BがAである、自体もチェック対象？それとも「もしBがAなら好き」と解釈して対象外？
        - 生コメントに根拠（引用、返信元、出典、リンクなど）がある場合、それを優先的に調べたいが、↑だと扱われてなさそう？
        - コメントが、文字通りの意味/反語/皮肉/比喩/大喜利 などどういう意味かは文脈依存だが、判別できるか？
        - → 前処理全般は広聴AIやいどばたの既存の仕組みに乗っかり、ここでは前処理後のコメントのみを扱うとする
    - 判定の考え方をどうするか？
        - 手動判定でも迷う
            - 「Aは必ずBだ」→ 99%正しい場合、「AはBだ」ならOKかもだが「必ず」が入るのでNG？
            - 「Aは必ずしもBでない」→ BでないAの実例がないが、ないとも証明できない場合は？
            - 「宇宙人に支配された日本は終わりだ。」をどう判断すべきか？
                - 「日本は宇宙人に支配されている。したがって終わりだ。」と解釈し、前段が事実に反するので偽？
                - 「もし日本が宇宙人に支配されたら、終わる。」と解釈すると、「終わる」の文脈次第で真偽が変わるので未確定？
                - 「もし日本が宇宙人に支配されたら、終わる。」と解釈するが、前提命題が偽なので論理命題としては真？
                - 「宇宙人」が地球外生命体ではなく比喩表現かもしれないので、未確定？
        - 「偽と確定できるものだけ弾く」大方針に従うなら、「偽と確定しない判定方法があるなら弾かない」が正解か？どこまで厳密にやるべきか・・
    - プロンプト関連
        - 各種プロンプトの精度向上
        - コメント数の何倍もLLMにAPI投げたくないので、まとめて処理する工夫など必要そう
    - LLMの種類
        - ひとまず OpenAI API の o4-mini に固定。モデル間の精度差の検証は次のステップとする
    - 判定基準系
        - 真実性の判定方法どうしよう　今は Truthinessのenumに適当に分類してる
            - とりあえずそのまま進めて、LLMの場合は理由も記録しておく
        - 評価指標どうしよう
            - 精度指標：NG率の低さ > 見逃し率の低さ
                - 正解が真/不明、判定が真/不明：OK
                - 正解が真/不明、判定が偽：NG
                - 正解が偽、判定が真/不明：まあOK（偽検出できればいいので）だが、減らしたい
            - コスト指標：時間、API料金

- ファクトチェック処理別の検討事項
    - 既存のファクトチェックサービス
        - Google Fact Check Tools、Poynter API、他には？
        - 便利だけど、見逃し率は高くなりそう
    - 固定サイトで確認
        - 利用者が複数指定できるようにする？
        - Wikipedia（暫定。怒られそう）
        - 各種ニュースサイト
        - 公式資料の類
        - 論文系は見極めが難しいのでパス
    - LLMに直接聞く
        - 怒られそう。でも最近賢いので一応
    - 既存のDeepResearch、推論モデル
        - OpenAI、Perplexity、Gemini、Groq、Felo、Elicit、他には？
    - 自前でDeepResearch作る
        - 後回し。他の結果が出揃ってから考える
    - 最終的には組み合わせる？
        - 分野の狭い単純事実は固定サイト/Web検索、軽い調査はDeepResearch、人力調査が大事なところはファクトチェックサービス、など
        - 後回し。他の結果が出揃ってから考える

- その他
    - ある程度形になったら https://github.com/digitaldemocracy2030/ のどこかに移植する
    - インプットは、comments.pyに直書きではなく_input/ からCSVを読み込みたい
    - アウトプットのCSVを可視化したい
